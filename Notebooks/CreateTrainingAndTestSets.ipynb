{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install necessary modules\n",
    "!pip install wget pandas numpy biopython\n",
    "# download the resources to the 'resources' folder\n",
    "!python -m wget https://zuchnerlab.s3.amazonaws.com/VariantPathogenicity/MaverickTrainingResources.tar.gz\n",
    "!tar -zxvf MaverickTrainingResources.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create OMIM inheritance map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "genemap=pandas.read_csv('resources/genemap2_20200114.txt',sep='\\t',low_memory=False,comment='#')\n",
    "genemap=genemap.loc[:,['MIM Number','Approved Symbol','Ensembl Gene ID','Phenotypes']]\n",
    "genemap=genemap.loc[~genemap['Approved Symbol'].isna(),:]\n",
    "genemap=genemap.loc[~genemap['Phenotypes'].isna(),:]\n",
    "genemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimToGene=genemap.loc[:,['MIM Number','Approved Symbol']]\n",
    "phenotypes=pandas.DataFrame(genemap['Phenotypes'].str.split(';').tolist(), index=genemap['MIM Number'].values).stack().str.strip()\n",
    "phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter=((phenotypes.str[0]==\"?\") | (phenotypes.str[0]==\"[\") | (phenotypes.str[0]==\"{\"))\n",
    "phenotypes2=phenotypes.loc[~filter,:]\n",
    "phenotypes2\n",
    "filter2=phenotypes2.str.contains(\" [0-9]{6} \\(\")\n",
    "phenotypes2=phenotypes2.loc[filter2,:]\n",
    "phenotypes2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locusMIMs=phenotypes2.index.get_level_values(0)\n",
    "phenotypeMIMs=phenotypes2.str.split(\"\\([0-9]\\)\").str[0].str.split(',').str[-1].str.strip()\n",
    "phenotypeInheritances=phenotypes2.str.split(\"\\([0-9]\\), \").str[1].str.strip()\n",
    "mappingMethod=phenotypes2.str.split(\" [0-9]{6} \\(\").str[1].str.split(')').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newMap=pandas.DataFrame({'geneMIM':locusMIMs,'phenoMIM':phenotypeMIMs.values,'inheritance':phenotypeInheritances.values,'mappingMethod':mappingMethod.values})\n",
    "newMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newMap.to_csv('resources/geneToPhenoToInheritanceMap.txt',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newMap2=newMap.loc[((newMap['inheritance']==\"Autosomal dominant\") | (newMap['inheritance']==\"Autosomal recessive\")),:]\n",
    "newMap3=newMap2.loc[newMap2['mappingMethod']=='3',:]\n",
    "# add back in the gene names\n",
    "mimToGene=mimToGene.rename(columns={'MIM Number':'geneMIM','Approved Symbol':'GeneSymbol'})\n",
    "newMap4=newMap3.merge(mimToGene,how='inner',on='geneMIM')\n",
    "newMap4.to_csv('resources/geneToPhenoToInheritanceMap_filtered.txt',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse 2020 Clinvar variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "inheritanceMap=pandas.read_csv('resources/geneToPhenoToInheritanceMap_filtered.txt',sep='\\t',low_memory=False)\n",
    "inheritanceMap=inheritanceMap.drop_duplicates(subset=['geneMIM','phenoMIM','inheritance'],keep='first')\n",
    "inheritanceMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinvar=pandas.read_csv('resources/variant_summary_2020-01.txt',sep='\\t',low_memory=False)\n",
    "clinvar.loc[:,'Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinvar=clinvar.loc[clinvar['Assembly']==\"GRCh37\",:]\n",
    "clinvar=clinvar.loc[((clinvar['Type']==\"single nucleotide variant\") | (clinvar['Type']==\"deletion\") | (clinvar['Type']==\"duplication\") | (clinvar['Type']==\"short repeat\") | (clinvar['Type']==\"indel\") | (clinvar['Type']==\"insertion\")),:]\n",
    "benign=clinvar.loc[((clinvar['ClinicalSignificance']==\"Benign\") | (clinvar['ClinicalSignificance']==\"Likely benign\") | (clinvar['ClinicalSignificance']==\"Benign/Likely benign\")),:]\n",
    "benign=benign.loc[~(benign['OriginSimple']==\"somatic\"),:]\n",
    "clinvar=clinvar.loc[((clinvar['ClinicalSignificance']==\"Pathogenic\") | (clinvar['ClinicalSignificance']==\"Likely pathogenic\") | (clinvar['ClinicalSignificance']==\"Pathogenic/Likely pathogenic\")),:]\n",
    "clinvar=clinvar.loc[~(clinvar['OriginSimple']==\"somatic\"),:]\n",
    "clinvar=clinvar.loc[clinvar['PhenotypeIDS'].str.contains(\"OMIM:\"),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the relationships between clinvar allele IDs and omim phenotype ids \n",
    "clinvarOmimPheno=pandas.DataFrame(clinvar['PhenotypeIDS'].str.split(';').tolist(), index=clinvar['AlleleID'].values).stack()\n",
    "clinvarOmimPheno=clinvarOmimPheno[clinvarOmimPheno.str.contains(\"OMIM:\")]\n",
    "clinvarAlleleIDs=clinvarOmimPheno.index.get_level_values(0)\n",
    "clinvarAlleleOmimIDs=clinvarOmimPheno.str.split(\"OMIM:\").str[1].str.split(\",\").str[0].str.strip()\n",
    "clinvarAllelesToOmimIDs=pandas.DataFrame({'clinvarAlleleID':clinvarAlleleIDs,'phenoMIM':clinvarAlleleOmimIDs.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select down to just the allele IDs for which we have at least one inheritance pattern in omim\n",
    "clinvarAllelesWithInheritance=clinvarAllelesToOmimIDs.merge(inheritanceMap,how='inner',on='phenoMIM')\n",
    "# select down to just the variants without conflicts in the inheritance\n",
    "clinvarAllelesWithInheritance2=clinvarAllelesWithInheritance.drop_duplicates(subset=['clinvarAlleleID','inheritance'],keep='first')\n",
    "clinvarAllelesWithInheritance3=clinvarAllelesWithInheritance2.drop_duplicates(subset='clinvarAlleleID',keep=False)\n",
    "# get the original data on the alleles with omim inheritance\n",
    "clinvar2=clinvar.merge(clinvarAllelesWithInheritance3,how='inner',left_on=['AlleleID'],right_on=['clinvarAlleleID'])\n",
    "clinvar2.loc[:,'ReviewStatus'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinvar3=clinvar2.loc[~(clinvar2['ReviewStatus']==\"no assertion criteria provided\"),:]\n",
    "len(clinvar3.loc[clinvar3['inheritance']=='Autosomal recessive',:]) # this is the number of recessive variants we have now (but this includes coding and noncoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clinvar3.loc[clinvar3['inheritance']=='Autosomal dominant',:]) # this is the number of dominant variants we have now (but this includes coding and noncoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinvar3AR=clinvar3.loc[clinvar3['inheritance']=='Autosomal recessive',['Chromosome','Start','ReferenceAllele','AlternateAllele']]\n",
    "clinvar3AD=clinvar3.loc[clinvar3['inheritance']=='Autosomal dominant',['Chromosome','Start','ReferenceAllele','AlternateAllele']]\n",
    "clinvar3AR=clinvar3AR.sort_values(by=['Chromosome','Start','ReferenceAllele','AlternateAllele'])\n",
    "clinvar3AD=clinvar3AD.sort_values(by=['Chromosome','Start','ReferenceAllele','AlternateAllele'])\n",
    "clinvar3AR.to_csv('resources/clinvar_pathogenic_AR_locations.txt',sep='\\t',index=False)\n",
    "clinvar3AD.to_csv('resources/clinvar_pathogenic_AD_locations.txt',sep='\\t',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with clinvar and gnomAD benigns\n",
    "benign=benign.loc[~(benign['ReviewStatus']==\"no assertion criteria provided\"),:]\n",
    "benign=benign.loc[:,['Chromosome','Start','ReferenceAllele','AlternateAllele']]\n",
    "benign.to_csv('resources/clinvar_oneToFourStarBenign_locations.txt',sep='\\t',index=False)\n",
    "gnomad=pandas.read_csv('resources/gnomADVariantsSeenAsHomAltTwiceInExomes.txt',sep='\\t',low_memory=False)\n",
    "benign2=pandas.concat([benign,gnomad],axis=0,ignore_index=True)\n",
    "benign2=benign2.sort_values(by=['Chromosome','Start','ReferenceAllele','AlternateAllele'])\n",
    "benign2=benign2.drop_duplicates(subset=['Chromosome','Start','ReferenceAllele','AlternateAllele'],keep='first').reset_index(drop=True)\n",
    "benign2.to_csv('resources/clinvar_benign_locations.txt',sep='\\t',index=False)\n",
    "len(benign2) # this is the number of benign variants we have now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the files into VCFs and process with Annovar\n",
    "%%bash \n",
    "cd resources\n",
    "dos2unix clinvar_oneToFourStar*\n",
    "tail -n +2 clinvar_pathogenic_AR_locations.txt | awk -F'\\t' -v OFS='\\t' '{print $1,$2,\".\",$3,$4,\".\",\"PASS\",\".\",\"GT\",\"0/1\"}' | cat header.vcf - > clinvar_pathogenic_AR.vcf\n",
    "tail -n +2 clinvar_pathogenic_AD_locations.txt | awk -F'\\t' -v OFS='\\t' '{print $1,$2,\".\",$3,$4,\".\",\"PASS\",\".\",\"GT\",\"0/1\"}' | cat header.vcf - > clinvar_pathogenic_AD.vcf\n",
    "tail -n +2 clinvar_benign_locations.txt | awk -F'\\t' -v OFS='\\t' '{print $1,$2,\".\",$3,$4,\".\",\"PASS\",\".\",\"GT\",\"0/1\"}' | cat header.vcf - > clinvar_benign.vcf\n",
    "\n",
    "annovar/convert2annovar.pl -format vcf4 clinvar_pathogenic_AR.vcf > clinvar_pathogenic_AR.avinput\n",
    "annovar/annotate_variation.pl -dbtype wgEncodeGencodeBasicV33lift37 -buildver hg19 --exonicsplicing clinvar_pathogenic_AR.avinput annovar/humandb/\n",
    "annovar/convert2annovar.pl -format vcf4 clinvar_pathogenic_AD.vcf > clinvar_pathogenic_AD.avinput\n",
    "annovar/annotate_variation.pl -dbtype wgEncodeGencodeBasicV33lift37 -buildver hg19 --exonicsplicing clinvar_pathogenic_AD.avinput annovar/humandb/\n",
    "annovar/convert2annovar.pl -format vcf4 clinvar_benign.vcf > clinvar_benign.avinput\n",
    "annovar/annotate_variation.pl -dbtype wgEncodeGencodeBasicV33lift37 -buildver hg19 --exonicsplicing clinvar_benign.avinput annovar/humandb/\n",
    "\n",
    "annovar/coding_change.pl clinvar_pathogenic_AR.avinput.exonic_variant_function annovar/humandb/hg19_wgEncodeGencodeBasicV33lift37.txt annovar/humandb/hg19_wgEncodeGencodeBasicV33lift37Mrna.fa --includesnp --onlyAltering --alltranscript > clinvar_pathogenic_AR.coding_changes.txt\n",
    "annovar/coding_change.pl clinvar_pathogenic_AD.avinput.exonic_variant_function annovar/humandb/hg19_wgEncodeGencodeBasicV33lift37.txt annovar/humandb/hg19_wgEncodeGencodeBasicV33lift37Mrna.fa --includesnp --onlyAltering --alltranscript > clinvar_pathogenic_AD.coding_changes.txt\n",
    "annovar/coding_change.pl clinvar_benign.avinput.exonic_variant_function annovar/humandb/hg19_wgEncodeGencodeBasicV33lift37.txt annovar/humandb/hg19_wgEncodeGencodeBasicV33lift37Mrna.fa --includesnp --onlyAltering --alltranscript > clinvar_benign.coding_changes.txt\n",
    "\n",
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "approvedTranscripts=pandas.read_csv('resources/gencodeBasicFullLengthTranscriptsConversionTable.txt',sep='\\t',low_memory=False)\n",
    "\n",
    "canonical=pandas.read_csv('resources/gnomad211_constraint_canonical_simple.txt',sep='\\t',low_memory=False)\n",
    "# remove the gnomad canonical transcripts that are not approvedTranscripts\n",
    "canonical=canonical.loc[canonical['transcript'].isin(approvedTranscripts['transcriptIDShort'].values),:].reset_index(drop=True)\n",
    "\n",
    "GTEx=pandas.read_csv('resources/GTEx.V7.tx_medians.021820.tsv',sep='\\t',low_memory=False)\n",
    "# remove the non-approvedTranscripts from the expression data\n",
    "GTEx=GTEx.loc[GTEx['transcript_id'].isin(approvedTranscripts['transcriptIDShort'].values),:].reset_index(drop=True)\n",
    "# add a overall expression column\n",
    "GTEx['overallAvg']=GTEx.iloc[:,2:55].mean()\n",
    "\n",
    "sequences={}\n",
    "for record in SeqIO.parse(\"resources/gencode.v33lift37.pc_translations.fa\",\"fasta\"):\n",
    "    transcriptID=record.id.split('|')[1]\n",
    "    if transcriptID in approvedTranscripts['transcriptID'].values:\n",
    "        sequences[transcriptID]=record.seq\n",
    "\n",
    "def groomAnnovarOutput(base,sequences=sequences,approvedTranscripts=approvedTranscripts,canonical=canonical,GTEx=GTEx):\n",
    "\n",
    "    sample=pandas.read_csv(\"resources/\" + base + \".avinput.exonic_variant_function\",sep='\\t',low_memory=False,header=None,\n",
    "                        names=['line','varType','location','hg19_chr','hg19_pos(1-based)','end','ref','alt','genotype','qual','depth'])\n",
    "    # convert the position, ref, and alt alleles to long form\n",
    "    longForm=pandas.read_csv(\"resources/\" + base + \"_locations.txt\",sep='\\t',low_memory=False)\n",
    "    longForm=longForm.rename(columns={'Chromosome':'chrom','Start':'pos_long','ReferenceAllele':'ref_long','AlternateAllele':'alt_long'})\n",
    "    sample['lineNum']=sample.loc[:,'line'].str[4:].astype(int)-1\n",
    "    sample=sample.merge(longForm,how='inner',left_on='lineNum',right_on=longForm.index)\n",
    "    sample=sample.loc[:,['line','varType','location','hg19_chr','pos_long','end','ref_long','alt_long','genotype','qual','depth']].rename(columns={'pos_long':'hg19_pos(1-based)','ref_long':'ref','alt_long':'alt'}).reset_index(drop=True)\n",
    "    # add new columns with placeholders to be filled in\n",
    "    sample['WildtypeSeq']=\"\"\n",
    "    sample['AltSeq']=\"\"\n",
    "    sample['ChangePos']=-1\n",
    "    sample['TranscriptID']=\"\"\n",
    "    sample['TranscriptIDShort']=sample['location'].str.split(':',expand=True)[1].str[:15]\n",
    "    sample['geneName']=sample['location'].str.split(':',expand=True)[0]\n",
    "    sample['geneID']=\"\"\n",
    "    sample['geneIDShort']=\"\"\n",
    "\n",
    "\n",
    "    for i in range(len(sample)):\n",
    "        if i % 1000 == 0:\n",
    "            print(str(i) + ' rows completed')\n",
    "        numTranscripts=len(sample.loc[i,'location'].split(','))\n",
    "        numCanonical=0\n",
    "        canonicals=[]\n",
    "        transcripts=[]\n",
    "        transcriptLengths=[]\n",
    "        canonicalTranscript=\"\"\n",
    "        correctedGeneName=\"\"\n",
    "        for j in range(numTranscripts-1):\n",
    "            if sample.loc[i,'location'].split(',')[j].split(':')[1][:15] in canonical['transcript'].values:\n",
    "                numCanonical=numCanonical+1\n",
    "                canonicals.append(sample.loc[i,'location'].split(',')[j].split(':')[1][:15])\n",
    "            if sample.loc[i,'location'].split(',')[j].split(':')[1] in approvedTranscripts['transcriptID'].values:  \n",
    "                transcripts.append(sample.loc[i,'location'].split(',')[j].split(':')[1][:15])\n",
    "                transcriptLengths.append(len(sequences[sample.loc[i,'location'].split(',')[j].split(':')[1]]))\n",
    "\n",
    "        if len(transcripts)>0:\n",
    "            if numCanonical==1:\n",
    "                transcriptID=canonicals[0]\n",
    "                sample.loc[i,'TranscriptIDShort']=transcriptID\n",
    "                sample.loc[i,'TranscriptID']=approvedTranscripts.loc[approvedTranscripts['transcriptIDShort']==transcriptID,'transcriptID'].values[0]\n",
    "                sample.loc[i,'geneName']=approvedTranscripts.loc[approvedTranscripts['transcriptIDShort']==transcriptID,'geneName'].values[0]\n",
    "                sample.loc[i,'geneID']=approvedTranscripts.loc[approvedTranscripts['transcriptIDShort']==transcriptID,'geneID'].values[0]\n",
    "                sample.loc[i,'geneIDShort']=approvedTranscripts.loc[approvedTranscripts['transcriptIDShort']==transcriptID,'geneIDShort'].values[0]\n",
    "            elif numCanonical==0:\n",
    "                if len(transcripts)==1:\n",
    "                    transcriptID=transcripts[0]\n",
    "                    sample.loc[i,'TranscriptIDShort']=transcriptID\n",
    "                    sample.loc[i,'TranscriptID']=approvedTranscripts.loc[approvedTranscripts['transcriptIDShort']==transcriptID,'transcriptID'].values[0]\n",
    "                    sample.loc[i,'geneName']=approvedTranscripts.loc[approvedTranscripts['transcriptIDShort']==transcriptID,'geneName'].values[0]\n",
    "                    sample.loc[i,'geneID']=approvedTranscripts.loc[approvedTranscripts['transcriptIDShort']==transcriptID,'geneID'].values[0]\n",
    "                    sample.loc[i,'geneIDShort']=approvedTranscripts.loc[approvedTranscripts['transcriptIDShort']==transcriptID,'geneIDShort'].values[0]\n",
    "                else:\n",
    "                    if len(GTEx.loc[GTEx['transcript_id'].isin(transcripts),:])>0:\n",
    "                        # pick the transcript with the highest expression\n",
    "                        transcriptID=GTEx.loc[GTEx['transcript_id'].isin(transcripts),:].sort_values(by=['overallAvg'],ascending=False).reset_index(drop=True).iloc[0,0]\n",
    "                        sample.loc[i,'TranscriptIDShort']=transcriptID\n",
    "                        sample.loc[i,'TranscriptID']=approvedTranscripts.loc[approvedTranscripts['transcriptIDShort']==transcriptID,'transcriptID'].values[0]\n",
    "                        sample.loc[i,'geneName']=approvedTranscripts.loc[approvedTranscripts['transcriptIDShort']==transcriptID,'geneName'].values[0]\n",
    "                        sample.loc[i,'geneID']=approvedTranscripts.loc[approvedTranscripts['transcriptIDShort']==transcriptID,'geneID'].values[0]\n",
    "                        sample.loc[i,'geneIDShort']=approvedTranscripts.loc[approvedTranscripts['transcriptIDShort']==transcriptID,'geneIDShort'].values[0]\n",
    "                    else:\n",
    "                        # if none of the transcripts have measured expression and none of them are canonical, then pick the one with the longest amino acid sequence\n",
    "                        # if multiple tie for longest, this picks the one we saw first\n",
    "                        j=transcriptLengths.index(max(transcriptLengths))\n",
    "                        transcriptID=transcripts[j]\n",
    "                        sample.loc[i,'TranscriptIDShort']=transcriptID\n",
    "                        sample.loc[i,'TranscriptID']=approvedTranscripts.loc[approvedTranscripts['transcriptIDShort']==transcriptID,'transcriptID'].values[0]\n",
    "                        sample.loc[i,'geneName']=approvedTranscripts.loc[approvedTranscripts['transcriptIDShort']==transcriptID,'geneName'].values[0]\n",
    "                        sample.loc[i,'geneID']=approvedTranscripts.loc[approvedTranscripts['transcriptIDShort']==transcriptID,'geneID'].values[0]\n",
    "                        sample.loc[i,'geneIDShort']=approvedTranscripts.loc[approvedTranscripts['transcriptIDShort']==transcriptID,'geneIDShort'].values[0]\n",
    "            elif numCanonical>1:\n",
    "                if len(GTEx.loc[GTEx['transcript_id'].isin(canonicals),:])>0:\n",
    "                    # pick the canonical transcript with the highest expression\n",
    "                    transcriptID=GTEx.loc[GTEx['transcript_id'].isin(canonicals),:].sort_values(by=['overallAvg'],ascending=False).reset_index(drop=True).iloc[0,0]\n",
    "                    sample.loc[i,'TranscriptIDShort']=transcriptID\n",
    "                    sample.loc[i,'TranscriptID']=approvedTranscripts.loc[approvedTranscripts['transcriptIDShort']==transcriptID,'transcriptID'].values[0]\n",
    "                    sample.loc[i,'geneName']=approvedTranscripts.loc[approvedTranscripts['transcriptIDShort']==transcriptID,'geneName'].values[0]\n",
    "                    sample.loc[i,'geneID']=approvedTranscripts.loc[approvedTranscripts['transcriptIDShort']==transcriptID,'geneID'].values[0]\n",
    "                    sample.loc[i,'geneIDShort']=approvedTranscripts.loc[approvedTranscripts['transcriptIDShort']==transcriptID,'geneIDShort'].values[0]\n",
    "                else:\n",
    "                    # if none of the canonical transcripts have measured expression, then pick the one with the longest amino acid sequence\n",
    "                    # if multiple tie for longest, this picks the one we saw first\n",
    "                    j=transcriptLengths.index(max(transcriptLengths))\n",
    "                    transcriptID=transcripts[j]\n",
    "                    sample.loc[i,'TranscriptIDShort']=transcriptID\n",
    "                    sample.loc[i,'TranscriptID']=approvedTranscripts.loc[approvedTranscripts['transcriptIDShort']==transcriptID,'transcriptID'].values[0]\n",
    "                    sample.loc[i,'geneName']=approvedTranscripts.loc[approvedTranscripts['transcriptIDShort']==transcriptID,'geneName'].values[0]\n",
    "                    sample.loc[i,'geneID']=approvedTranscripts.loc[approvedTranscripts['transcriptIDShort']==transcriptID,'geneID'].values[0]\n",
    "                    sample.loc[i,'geneIDShort']=approvedTranscripts.loc[approvedTranscripts['transcriptIDShort']==transcriptID,'geneIDShort'].values[0]\n",
    "\n",
    "    for record in SeqIO.parse(\"resources/\" + base + \".coding_changes.txt\", \"fasta\"):\n",
    "        lineNum=record.id\n",
    "        # only use the transcript that we selected above \n",
    "        if sample.loc[sample['line']==lineNum,'TranscriptID'].values==record.description.split(' ')[1]:\n",
    "            if 'WILDTYPE' in record.description:\n",
    "                if record.seq.__str__()[:-1] == sequences[record.description.split(' ')[1]]:\n",
    "                    sample.loc[sample['line']==lineNum,'WildtypeSeq']=record.seq.__str__()\n",
    "                    sample.loc[sample['line']==lineNum,'TranscriptID']=record.description.split(' ')[1]\n",
    "            else:\n",
    "                sample.loc[sample['line']==lineNum,'AltSeq']=record.seq.__str__()\n",
    "                if 'startloss' in record.description:\n",
    "                    sample.loc[sample['line']==lineNum,'ChangePos']=1\n",
    "                elif 'silent' in record.description:\n",
    "                    sample.loc[sample['line']==lineNum,'ChangePos']=-1\n",
    "                else:\n",
    "                    sample.loc[sample['line']==lineNum,'ChangePos']=record.description.split(' ')[7].split('-')[0]\n",
    "    sample2=sample.loc[~((sample['WildtypeSeq']==\"\") | (sample['AltSeq']==\"\") | (sample['ChangePos']==-1)),:]\n",
    "    sample2.to_csv(\"resources/\" + base + '.groomed.txt',sep='\\t',index=False)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groomAnnovarOutput('clinvar_pathogenic_AR')\n",
    "groomAnnovarOutput('clinvar_pathogenic_AD')\n",
    "groomAnnovarOutput('clinvar_benign')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "constraint=pandas.read_csv('resources/gnomad211_constraint_canonical_simple.txt',sep='\\t',low_memory=False)\n",
    "\n",
    "gnomadAF=pandas.read_csv('resources/gnomad211_exomes_AFs.txt',sep='\\t',low_memory=False)\n",
    "gnomadAF.loc[gnomadAF['hg19_chr']=='X','hg19_chr']=23\n",
    "gnomadAF.loc[gnomadAF['hg19_chr']=='Y','hg19_chr']=24\n",
    "gnomadAF.loc[gnomadAF['hg19_chr']=='MT','hg19_chr']=25\n",
    "gnomadAF['hg19_chr']=gnomadAF['hg19_chr'].astype(int)\n",
    "\n",
    "CCR=pandas.read_csv('resources/ccrs.enumerated.txt',sep='\\t',low_memory=False)\n",
    "CCR.loc[CCR['chrom']=='X','chrom']=23\n",
    "CCR['chrom']=CCR.loc[:,'chrom'].astype(int)\n",
    "CCR=CCR.sort_values(by=['chrom','pos','ccr_pct'],ascending=[True,True,False]).drop_duplicates(subset=['chrom','pos'],keep='first').reset_index(drop=True)\n",
    "\n",
    "pext=pandas.read_csv('resources/gnomAD_pext_values.txt',sep='\\t',low_memory=False)\n",
    "pext.loc[pext['chr']=='X','chr']=23\n",
    "pext.loc[pext['chr']=='Y','chr']=24\n",
    "pext.loc[pext['chr']=='MT','chr']=25\n",
    "pext['chr']=pext.loc[:,'chr'].astype(int)\n",
    "pext=pext.sort_values(by=['chr','pos','pext'],ascending=[True,True,False]).drop_duplicates(subset=['chr','pos'],keep='first').reset_index(drop=True)\n",
    "\n",
    "gerp=pandas.read_csv('resources/gerpOnExons.txt',sep='\\t',low_memory=False,header=None,names=['chr','pos','gerp'])\n",
    "gerp.loc[gerp['chr']=='X','chr']=23\n",
    "gerp.loc[gerp['chr']=='Y','chr']=24\n",
    "gerp.loc[gerp['chr']=='MT','chr']=25\n",
    "gerp['chr']=gerp['chr'].astype(int)\n",
    "gerp=gerp.sort_values(by=['chr','pos','gerp'],ascending=[True,True,False]).drop_duplicates(subset=['chr','pos'],keep='first').reset_index(drop=True)\n",
    "\n",
    "GDI=pandas.read_csv('resources/GDI.groomed.txt',sep='\\t',low_memory=False)\n",
    "RVIS=pandas.read_csv('resources/RVIS.groomed.txt',sep='\\t',low_memory=False)\n",
    "\n",
    "def annotateVariantsAndFilter(base,constraint=constraint,gnomadAF=gnomadAF,CCR=CCR,pext=pext,gerp=gerp,GDI=GDI,RVIS=RVIS,variantType='normal'):\n",
    "    import pandas\n",
    "    import numpy as np\n",
    "    sample=pandas.read_csv('resources/' + base + '.groomed.txt',sep='\\t',low_memory=False)\n",
    "    sample.loc[sample['hg19_chr']=='X','hg19_chr']=23\n",
    "    sample.loc[sample['hg19_chr']=='Y','hg19_chr']=24\n",
    "    sample.loc[sample['hg19_chr']=='MT','hg19_chr']=25\n",
    "    sample['hg19_chr']=sample['hg19_chr'].astype(int)\n",
    "\n",
    "    # merge on the allele frequency data\n",
    "    sample=sample.merge(gnomadAF,how='left',on=['hg19_chr','hg19_pos(1-based)','ref','alt'])\n",
    "\n",
    "    # merge on the constraint data (try transcript ID merge first)\n",
    "    sampleTranscript=sample.merge(constraint,how='inner',left_on=['TranscriptIDShort'],right_on=['transcript'])\n",
    "    notMatched=sample.loc[~(sample['TranscriptIDShort'].isin(sampleTranscript['TranscriptIDShort'])),:]\n",
    "    constraint=pandas.read_csv('gnomad211_constraint_simple_geneLevel.txt',sep='\\t',low_memory=False)\n",
    "    sampleGeneID=notMatched.merge(constraint,how='inner',left_on=['geneIDShort'],right_on=['gene_id'])\n",
    "    notMatched2=notMatched.loc[~(notMatched['geneIDShort'].isin(sampleGeneID['geneIDShort'])),:]\n",
    "    sampleGeneName=notMatched2.merge(constraint,how='left',left_on=['geneName'],right_on=['gene'])\n",
    "    # stack them all back together\n",
    "    sample2=pandas.concat([sampleTranscript,sampleGeneID,sampleGeneName],axis=0,ignore_index=True)\n",
    "    sample2.loc[sample2['hg19_chr']=='X','hg19_chr']=23\n",
    "    sample2.loc[sample2['hg19_chr']=='Y','hg19_chr']=24\n",
    "    sample2.loc[sample2['hg19_chr']=='MT','hg19_chr']=25\n",
    "    sample2['hg19_chr']=sample2['hg19_chr'].astype(int)\n",
    "\n",
    "    # merge on the CCR data\n",
    "    sample2['CCR']=np.nan\n",
    "    sampleSNVs=sample2.loc[sample2['varType'].isin(['nonsynonymous SNV','synonymous SNV','stopgain','stoploss']),['hg19_chr','hg19_pos(1-based)']]\n",
    "    sampleIndels=sample2.loc[sample2['varType'].isin(['frameshift insertion','frameshift deletion','frameshift substitution',\n",
    "                                                    'nonframeshift insertion','nonframeshift deletion','nonframeshift substitution']),['hg19_chr','hg19_pos(1-based)','ref']]\n",
    "    sampleIndels['length']=sampleIndels['ref'].str.len()\n",
    "    sampleIndels['CCR']=np.nan\n",
    "    sampleSNVs2=sampleSNVs.merge(CCR,how='left',left_on=['hg19_chr','hg19_pos(1-based)'],right_on=['chrom','pos']).set_index(sampleSNVs.index)\n",
    "    for i in range(len(sampleIndels)):\n",
    "        if i%100==0:\n",
    "            print(str(i) + ' rows complete of ' + str(len(sampleIndels)))\n",
    "        startPos=sampleIndels.iloc[i,1]+1\n",
    "        endPos=startPos+sampleIndels.iloc[i,3]\n",
    "        sampleIndels.iloc[i,4]=CCR.loc[((CCR['chrom']==sampleIndels.iloc[i,0]) & (CCR['pos'].isin(range(startPos,endPos)))),'ccr_pct'].max()\n",
    "    sample2.loc[sampleSNVs2.index,'CCR']=sampleSNVs2.loc[:,'ccr_pct'].values\n",
    "    sample2.loc[sampleIndels.index,'CCR']=sampleIndels.loc[:,'CCR'].values\n",
    "\n",
    "    # merge on the pext data\n",
    "    sample2['pext']=np.nan\n",
    "    sampleIndels['pext']=np.nan\n",
    "    sampleSNVs2=sampleSNVs.merge(pext,how='left',left_on=['hg19_chr','hg19_pos(1-based)'],right_on=['chr','pos']).set_index(sampleSNVs.index)\n",
    "    for i in range(len(sampleIndels)):\n",
    "        if i%100==0:\n",
    "            print(str(i) + ' rows complete of ' + str(len(sampleIndels)))\n",
    "        startPos=sampleIndels.iloc[i,1]+1\n",
    "        endPos=startPos+sampleIndels.iloc[i,3]\n",
    "        sampleIndels.iloc[i,5]=pext.loc[((pext['chr']==sampleIndels.iloc[i,0]) & (pext['pos'].isin(range(startPos,endPos)))),'pext'].max()\n",
    "    sample2.loc[sampleSNVs2.index,'pext']=sampleSNVs2.loc[:,'pext'].values\n",
    "    sample2.loc[sampleIndels.index,'pext']=sampleIndels.loc[:,'pext'].values\n",
    "\n",
    "    # merge on the GERP data\n",
    "    sample2['gerp']=np.nan\n",
    "    sampleIndels['gerp']=np.nan\n",
    "    sampleSNVs2=sampleSNVs.merge(gerp,how='left',left_on=['hg19_chr','hg19_pos(1-based)'],right_on=['chr','pos']).set_index(sampleSNVs.index)\n",
    "    for i in range(len(sampleIndels)):\n",
    "        if i%100==0:\n",
    "            print(str(i) + ' rows complete of ' + str(len(sampleIndels)))\n",
    "        startPos=sampleIndels.iloc[i,1]+1\n",
    "        endPos=startPos+sampleIndels.iloc[i,3]\n",
    "        sampleIndels.iloc[i,6]=gerp.loc[((gerp['chr']==sampleIndels.iloc[i,0]) & (gerp['pos'].isin(range(startPos,endPos)))),'gerp'].max()\n",
    "    sample2.loc[sampleSNVs2.index,'gerp']=sampleSNVs2.loc[:,'gerp'].values\n",
    "    sample2.loc[sampleIndels.index,'gerp']=sampleIndels.loc[:,'gerp'].values\n",
    "\n",
    "    sample2=sample2.drop_duplicates(subset=['hg19_chr','hg19_pos(1-based)','ref','alt'],keep='first')\n",
    "    sample2=sample2.drop(columns=['line','location','end','qual','depth','gene','transcript', 'canonical','gene_id'])\n",
    "    sample2=sample2.sort_values(by=['hg19_chr','hg19_pos(1-based)','ref','alt']).reset_index(drop=True)\n",
    "\n",
    "    # merge on GDI data\n",
    "    sample2=sample2.merge(GDI,how='left',on='geneName')\n",
    "    # merge on RVIS data\n",
    "    sample2=sample2.merge(RVIS,how='left',on='geneName')\n",
    "    \n",
    "    # filtration steps that are only performed on the training and testing sets\n",
    "    # remove variants within 2bp of exon-intron boundaries\n",
    "    sample2=sample2.loc[~(sample2['varType'].str.contains('splicing')),:].reset_index(drop=True)\n",
    "    \n",
    "    # correct the sequence of proteins whose alt sequence doesn't start with an M to being non-translated\n",
    "    sample2.loc[((sample2['ChangePos']==1) & (sample2['ref'].str.len()==1) & (sample2['alt'].str.len()==1) & (sample2['ref']!='-') * (sample2['alt']!='-')),'AltSeq']=\"*\"\n",
    "    \n",
    "    if variantType=='dominant':\n",
    "        # get rid of any variants seen in gnomAD\n",
    "        sample2['controls_AF']=sample2['controls_AF'].replace('.',0).fillna(0)\n",
    "        sample2=sample2.loc[sample2['controls_AF']==0,:].reset_index(drop=True)\n",
    "    elif variantType=='recessive':\n",
    "        # get rid of any variants seen in the homozygous state in gnomAD\n",
    "        sample2['controls_nhomalt']=sample2['controls_nhomalt'].replace('.',0).fillna(0)\n",
    "        sample2=sample2.loc[sample2['controls_nhomalt']==0,:].reset_index(drop=True)\n",
    "\n",
    "    sample2=sample2.sort_values(by=['hg19_chr','hg19_pos(1-based)','ref','alt']).reset_index(drop=True)\n",
    "    sample2=sample2.drop_duplicates(subset=['hg19_chr','hg19_pos(1-based)','ref','alt'],keep='first').reset_index(drop=True)\n",
    "    sample2.to_csv('resources/' + base + '.annotated.txt',sep='\\t',index=False)\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotateVariantsAndFilter('clinvar_pathogenic_AR',variantType='recessive')\n",
    "annotateVariantsAndFilter('clinvar_pathogenic_AD',variantType='dominant')\n",
    "annotateVariantsAndFilter('clinvar_benign')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates and create validation set and training sets\n",
    "AR=pandas.read_csv('resources/clinvar_pathogenic_AR.annotated.txt',sep='\\t',low_memory=False)\n",
    "AD=pandas.read_csv('resources/clinvar_pathogenic_AD.annotated.txt',sep='\\t',low_memory=False)\n",
    "benign=pandas.read_csv('resources/clinvar_benign.annotated.txt',sep='\\t',low_memory=False)\n",
    "AR['classLabel']=2\n",
    "AD['classLabel']=1\n",
    "benign['classLabel']=0\n",
    "allData=pandas.concat([AR,AD,benign],axis=0,ignore_index=True)\n",
    "allData=allData.sort_values(by=['hg19_chr','hg19_pos(1-based)','ref','alt'])\n",
    "allData=allData.drop_duplicates(subset=['hg19_chr','hg19_pos(1-based)','ref','alt'],keep=False).reset_index(drop=True)\n",
    "allData=allData.loc[:,['varType', 'hg19_chr', 'hg19_pos(1-based)', 'ref', 'alt', 'WildtypeSeq', 'AltSeq', 'ChangePos', 'TranscriptID', 'TranscriptIDShort',\n",
    "       'geneName', 'geneID', 'geneIDShort', 'pLI', 'pNull', 'pRec', 'mis_z', 'lof_z', 'controls_AF', 'controls_nhomalt', 'CCR', 'pext', 'gerp', 'GDI', 'RVIS_ExAC_0.05', 'classLabel']]\n",
    "\n",
    "\n",
    "validationSet=allData.sample(n=1000,replace=False,random_state=1).sort_values(by=['hg19_chr','hg19_pos(1-based)','ref','alt'],ascending=True)\n",
    "trainingSet=allData.drop(validationSet.index).sort_values(by=['hg19_chr','hg19_pos(1-based)','ref','alt'],ascending=True)\n",
    "trainingSet.to_csv('resources/trainingSet.txt',sep='\\t',index=False)\n",
    "validationSet.to_csv('resources/validationSet.txt',sep='\\t',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet.loc[:,'classLabel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validationSet.loc[:,'classLabel'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat with 2021 Clinvar variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that clinvar updated their format between 1/2020 and 1/2021, so some of this is different from the above to compensate for that\n",
    "import pandas\n",
    "inheritanceMap=pandas.read_csv('resources/geneToPhenoToInheritanceMap_filtered.txt',sep='\\t',low_memory=False)\n",
    "inheritanceMap=inheritanceMap.drop_duplicates(subset=['geneMIM','phenoMIM','inheritance'],keep='first')\n",
    "inheritanceMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinvar=pandas.read_csv('resources/variant_summary_2021-01.txt',sep='\\t',low_memory=False)\n",
    "clinvar.loc[:,'Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinvar=clinvar.loc[clinvar['Assembly']==\"GRCh37\",:]\n",
    "clinvar=clinvar.loc[((clinvar['Type']==\"single nucleotide variant\") | (clinvar['Type']==\"Deletion\") | (clinvar['Type']==\"Duplication\") | (clinvar['Type']==\"Microsatellite\") | (clinvar['Type']==\"Indel\") | (clinvar['Type']==\"Insertion\")),:]\n",
    "benign=clinvar.loc[((clinvar['ClinicalSignificance']==\"Benign\") | (clinvar['ClinicalSignificance']==\"Likely benign\") | (clinvar['ClinicalSignificance']==\"Benign/Likely benign\")),:]\n",
    "benign=benign.loc[~(benign['OriginSimple']==\"somatic\"),:]\n",
    "clinvar=clinvar.loc[((clinvar['ClinicalSignificance']==\"Pathogenic\") | (clinvar['ClinicalSignificance']==\"Likely pathogenic\") | (clinvar['ClinicalSignificance']==\"Pathogenic/Likely pathogenic\")),:]\n",
    "clinvar=clinvar.loc[~(clinvar['OriginSimple']==\"somatic\"),:]\n",
    "clinvar=clinvar.loc[clinvar['PhenotypeIDS'].str.contains(\"OMIM:\"),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the relationships between clinvar allele IDs and omim phenotype ids \n",
    "clinvarOmimPheno=pandas.DataFrame(clinvar['PhenotypeIDS'].str.split(';').tolist(), index=clinvar['AlleleID'].values).stack()\n",
    "clinvarOmimPheno=clinvarOmimPheno[clinvarOmimPheno.str.contains(\"OMIM:\")]\n",
    "clinvarAlleleIDs=clinvarOmimPheno.index.get_level_values(0)\n",
    "clinvarAlleleOmimIDs=clinvarOmimPheno.str.split(\"OMIM:\").str[1].str.split(\",\").str[0].str.strip()\n",
    "clinvarAllelesToOmimIDs=pandas.DataFrame({'clinvarAlleleID':clinvarAlleleIDs,'phenoMIM':clinvarAlleleOmimIDs.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select down to just the allele IDs for which we have at least one inheritance pattern in omim\n",
    "clinvarAllelesWithInheritance=clinvarAllelesToOmimIDs.merge(inheritanceMap,how='inner',on='phenoMIM')\n",
    "# select down to just the variants without conflicts in the inheritance\n",
    "clinvarAllelesWithInheritance2=clinvarAllelesWithInheritance.drop_duplicates(subset=['clinvarAlleleID','inheritance'],keep='first')\n",
    "clinvarAllelesWithInheritance3=clinvarAllelesWithInheritance2.drop_duplicates(subset='clinvarAlleleID',keep=False)\n",
    "# get the original data on the alleles with omim inheritance\n",
    "clinvar2=clinvar.merge(clinvarAllelesWithInheritance3,how='inner',left_on=['AlleleID'],right_on=['clinvarAlleleID'])\n",
    "clinvar2.loc[:,'ReviewStatus'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinvar3=clinvar2.loc[~(clinvar2['ReviewStatus']==\"no assertion criteria provided\"),:]\n",
    "len(clinvar3.loc[clinvar3['inheritance']=='Autosomal recessive',:]) # this is the number of recessive variants we have now (but this includes coding and noncoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clinvar3.loc[clinvar3['inheritance']=='Autosomal dominant',:]) # this is the number of dominant variants we have now (but this includes coding and noncoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinvar3AR=clinvar3.loc[clinvar3['inheritance']=='Autosomal recessive',['Chromosome','PositionVCF','ReferenceAlleleVCF','AlternateAlleleVCF']]\n",
    "clinvar3AD=clinvar3.loc[clinvar3['inheritance']=='Autosomal dominant',['Chromosome','PositionVCF','ReferenceAlleleVCF','AlternateAlleleVCF']]\n",
    "clinvar3AR=clinvar3AR.rename(columns={'PositionVCF':'Start','ReferenceAlleleVCF':'ReferenceAllele','AlternateAlleleVCF':'AlternateAllele'}).sort_values(by=['Chromosome','Start','ReferenceAllele','AlternateAllele'])\n",
    "clinvar3AD=clinvar3AD.rename(columns={'PositionVCF':'Start','ReferenceAlleleVCF':'ReferenceAllele','AlternateAlleleVCF':'AlternateAllele'}).sort_values(by=['Chromosome','Start','ReferenceAllele','AlternateAllele'])\n",
    "clinvar3AR.to_csv('resources/clinvar_2021_oneToFourStarPathogenicVariants_autosomalRecessive_locations.txt',sep='\\t',index=False)\n",
    "clinvar3AD.to_csv('resources/clinvar_2021_oneToFourStarPathogenicVariants_autosomalDominant_locations.txt',sep='\\t',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with clinvar benigns (no need to incorporate gnomAD again)\n",
    "benign=benign.loc[~(benign['ReviewStatus']==\"no assertion criteria provided\"),:]\n",
    "benign=benign.loc[:,['Chromosome','PositionVCF','ReferenceAlleleVCF','AlternateAlleleVCF']]\n",
    "benign=benign.rename(columns={'PositionVCF':'Start','ReferenceAlleleVCF':'ReferenceAllele','AlternateAlleleVCF':'AlternateAllele'})\n",
    "benign=benign.sort_values(by=['Chromosome','Start','ReferenceAllele','AlternateAllele'])\n",
    "benign=benign.drop_duplicates(subset=['Chromosome','Start','ReferenceAllele','AlternateAllele'],keep='first').reset_index(drop=True)\n",
    "benign.to_csv('resources/clinvar_2021_oneToFourStarBenign_locations.txt',sep='\\t',index=False)\n",
    "len(benign) # this is the number of benign variants we have now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the old variants\n",
    "trainingSet=pandas.read_csv('resources/trainingSet.txt',sep='\\t',low_memory=False)\n",
    "validationSet=pandas.read_csv('resources/validationSet.txt',sep='\\t',low_memory=False)\n",
    "trainingSet=pandas.concat([trainingSet,validationSet],axis=0,ignore_index=True)\n",
    "trainingSet=trainingSet.loc[:,['hg19_chr','hg19_pos(1-based)','ref','alt']].rename(columns={'hg19_chr':'Chromosome','hg19_pos(1-based)':'Start','ref':'ReferenceAllele','alt':'AlternateAllele'})\n",
    "\n",
    "benign=pandas.read_csv('resources/clinvar_2021_oneToFourStarBenign_locations.txt',sep='\\t',low_memory=False)\n",
    "benign=benign.loc[~(benign['Chromosome'].isin(['X','Y','MT'])),:]\n",
    "benign=benign.loc[~(benign['Start']==-1),:]\n",
    "benign=benign.loc[~(benign['ReferenceAllele']=='na'),:]\n",
    "benign=benign.loc[~(benign['AlternateAllele']=='na'),:].reset_index(drop=True)\n",
    "benign['Chromosome']=benign['Chromosome'].astype(int)\n",
    "benign['Start']=benign['Start'].astype(int)\n",
    "benign2=benign.merge(trainingSet,how='left',on=['Chromosome','Start','ReferenceAllele','AlternateAllele'],indicator=True)\n",
    "benign3=benign2.loc[benign2['_merge']=='left_only',:].drop(columns=['_merge'])\n",
    "benign3.to_csv('resources/clinvar_2021_oneToFourStarBenign_locations_new.txt',sep='\\t',index=False)\n",
    "\n",
    "AD=pandas.read_csv('resources/clinvar_2021_oneToFourStarPathogenicVariants_autosomalDominant_locations.txt',sep='\\t',low_memory=False)\n",
    "AD=AD.loc[~(AD['Chromosome'].isin(['X','Y','MT'])),:]\n",
    "AD=AD.loc[~(AD['Start']==-1),:]\n",
    "AD=AD.loc[~(AD['ReferenceAllele']=='na'),:]\n",
    "AD=AD.loc[~(AD['AlternateAllele']=='na'),:].reset_index(drop=True)\n",
    "AD['Chromosome']=AD['Chromosome'].astype(int)\n",
    "AD['Start']=AD['Start'].astype(int)\n",
    "AD2=AD.merge(trainingSet,how='left',on=['Chromosome','Start','ReferenceAllele','AlternateAllele'],indicator=True)\n",
    "AD3=AD2.loc[AD2['_merge']=='left_only',:].drop(columns=['_merge'])\n",
    "AD3.to_csv('resources/clinvar_2021_oneToFourStarPathogenicVariants_autosomalDominant_locations_new.txt',sep='\\t',index=False)\n",
    "\n",
    "AR=pandas.read_csv('resources/clinvar_2021_oneToFourStarPathogenicVariants_autosomalRecessive_locations.txt',sep='\\t',low_memory=False)\n",
    "AR=AR.loc[~(AR['Chromosome'].isin(['X','Y','MT'])),:]\n",
    "AR=AR.loc[~(AR['Start']==-1),:]\n",
    "AR=AR.loc[~(AR['ReferenceAllele']=='na'),:]\n",
    "AR=AR.loc[~(AR['AlternateAllele']=='na'),:].reset_index(drop=True)\n",
    "AR['Chromosome']=AR['Chromosome'].astype(int)\n",
    "AR['Start']=AR['Start'].astype(int)\n",
    "AR2=AR.merge(trainingSet,how='left',on=['Chromosome','Start','ReferenceAllele','AlternateAllele'],indicator=True)\n",
    "AR3=AR2.loc[AR2['_merge']=='left_only',:].drop(columns=['_merge'])\n",
    "AR3.to_csv('resources/clinvar_2021_oneToFourStarPathogenicVariants_autosomalRecessive_locations_new.txt',sep='\\t',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the files into VCFs and process with Annovar\n",
    "%%bash\n",
    "cd resources/\n",
    "dos2unix clinvar_oneToFourStar*\n",
    "tail -n +2 clinvar_2021_oneToFourStarPathogenicVariants_autosomalRecessive_locations_new.txt | awk -F'\\t' -v OFS='\\t' '{print $1,$2,\".\",$3,$4,\".\",\"PASS\",\".\",\"GT\",\"0/1\"}' | cat ../header.vcf - > clinvar_2021_pathogenic_AR.vcf\n",
    "tail -n +2 clinvar_2021_oneToFourStarPathogenicVariants_autosomalDominant_locations_new.txt | awk -F'\\t' -v OFS='\\t' '{print $1,$2,\".\",$3,$4,\".\",\"PASS\",\".\",\"GT\",\"0/1\"}' | cat ../header.vcf - > clinvar_2021_pathogenic_AD.vcf\n",
    "tail -n +2 clinvar_2021_oneToFourStarBenign_locations_new.txt | awk -F'\\t' -v OFS='\\t' '{print $1,$2,\".\",$3,$4,\".\",\"PASS\",\".\",\"GT\",\"0/1\"}' | cat ../header.vcf - > clinvar_2021_benign.vcf\n",
    "\n",
    "annovar/convert2annovar.pl -format vcf4 clinvar_2021_pathogenic_AR.vcf > clinvar_2021_pathogenic_AR.avinput\n",
    "annovar/annotate_variation.pl -dbtype wgEncodeGencodeBasicV33lift37 -buildver hg19 --exonicsplicing clinvar_2021_pathogenic_AR.avinput annovar/humandb/\n",
    "annovar/convert2annovar.pl -format vcf4 clinvar_pathogenic_AD.vcf > clinvar_pathogenic_AD.avinput\n",
    "annovar/annotate_variation.pl -dbtype wgEncodeGencodeBasicV33lift37 -buildver hg19 --exonicsplicing clinvar_2021_pathogenic_AD.avinput annovar/humandb/\n",
    "annovar/convert2annovar.pl -format vcf4 clinvar_benign.vcf > clinvar_benign.avinput\n",
    "annovar/annotate_variation.pl -dbtype wgEncodeGencodeBasicV33lift37 -buildver hg19 --exonicsplicing clinvar_2021_benign.avinput annovar/humandb/\n",
    "\n",
    "annovar/coding_change.pl clinvar_2021_pathogenic_AR.avinput.exonic_variant_function annovar/humandb/hg19_wgEncodeGencodeBasicV33lift37.txt annovar/humandb/hg19_wgEncodeGencodeBasicV33lift37Mrna.fa --includesnp --onlyAltering --alltranscript > clinvar_2021_pathogenic_AR.coding_changes.txt\n",
    "annovar/coding_change.pl clinvar_2021_pathogenic_AD.avinput.exonic_variant_function annovar/humandb/hg19_wgEncodeGencodeBasicV33lift37.txt annovar/humandb/hg19_wgEncodeGencodeBasicV33lift37Mrna.fa --includesnp --onlyAltering --alltranscript > clinvar_2021_pathogenic_AD.coding_changes.txt\n",
    "annovar/coding_change.pl clinvar_2021_benign.avinput.exonic_variant_function annovar/humandb/hg19_wgEncodeGencodeBasicV33lift37.txt annovar/humandb/hg19_wgEncodeGencodeBasicV33lift37Mrna.fa --includesnp --onlyAltering --alltranscript > clinvar_2021_benign.coding_changes.txt\n",
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groomAnnovarOutput('clinvar_2021_pathogenic_AR')\n",
    "groomAnnovarOutput('clinvar_2021_pathogenic_AD')\n",
    "groomAnnovarOutput('clinvar_2021_benign')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotateVariantsAndFilter('clinvar_2021_pathogenic_AR',variantType='recessive')\n",
    "annotateVariantsAndFilter('clinvar_2021_pathogenic_AD',variantType='dominant')\n",
    "annotateVariantsAndFilter('clinvar_2021_benign')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create known and novel gene test sets\n",
    "AR=pandas.read_csv('resources/clinvar_2021_pathogenic_AR.annotated.txt',sep='\\t',low_memory=False)\n",
    "AD=pandas.read_csv('resources/clinvar_2021_pathogenic_AD.annotated.txt',sep='\\t',low_memory=False)\n",
    "benign=pandas.read_csv('resources/clinvar_2021_benign.annotated.txt',sep='\\t',low_memory=False)\n",
    "AR['classLabel']=2\n",
    "AD['classLabel']=1\n",
    "benign['classLabel']=0\n",
    "allData=pandas.concat([AR,AD,benign],axis=0,ignore_index=True)\n",
    "allData=allData.sort_values(by=['hg19_chr','hg19_pos(1-based)','ref','alt'])\n",
    "allData=allData.drop_duplicates(subset=['hg19_chr','hg19_pos(1-based)','ref','alt'],keep=False).reset_index(drop=True)\n",
    "allData=allData.loc[:,['varType', 'hg19_chr', 'hg19_pos(1-based)', 'ref', 'alt', 'WildtypeSeq', 'AltSeq', 'ChangePos', 'TranscriptID', 'TranscriptIDShort',\n",
    "       'geneName', 'geneID', 'geneIDShort', 'pLI', 'pNull', 'pRec', 'mis_z', 'lof_z', 'controls_AF', 'controls_nhomalt', 'CCR', 'pext', 'gerp', 'GDI', 'RVIS_ExAC_0.05', 'classLabel']]\n",
    "\n",
    "# split into known and novel gene sets\n",
    "trainingSet=pandas.read_csv('resources/trainingSet.txt',sep='\\t',low_memory=False)\n",
    "validationSet=pandas.read_csv('resources/validationSet.txt',sep='\\t',low_memory=False)\n",
    "trainingSet=pandas.concat([trainingSet,validationSet],axis=0,ignore_index=True)\n",
    "trainingSet=trainingSet.loc[trainingSet['classLabel']>0,:].reset_index(drop=True)\n",
    "\n",
    "known=allData.loc[allData['geneName'].isin(trainingSet['geneName'].values),:].reset_index(drop=True)\n",
    "novel=allData.loc[~(allData['geneName'].isin(trainingSet['geneName'].values)),:].reset_index(drop=True)\n",
    "\n",
    "known=known.sort_values(by=['hg19_chr','hg19_pos(1-based)','ref','alt'],ascending=True)\n",
    "known.to_csv('resources/knownGenes.txt',sep='\\t',index=False)\n",
    "novel=novel.sort_values(by=['hg19_chr','hg19_pos(1-based)','ref','alt'],ascending=True)\n",
    "novel.to_csv('resources/novelGenes.txt',sep='\\t',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known.loc[:,'classLabel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novel.loc[:,'classLabel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
